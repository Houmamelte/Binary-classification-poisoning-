{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4ccacd7aad0fea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T18:12:26.324974Z",
     "start_time": "2025-04-04T18:12:24.546079Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import ast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "344497ec943e3536",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T18:12:26.341005Z",
     "start_time": "2025-04-04T18:12:26.333979Z"
    }
   },
   "outputs": [],
   "source": [
    "input_file = \"../data/toxic_comments_cleaned.csv\"\n",
    "output_file = \"../data/processed.csv\"\n",
    "vocab_file = '../data/vocab.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef952345c9c35dc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T18:16:47.249503Z",
     "start_time": "2025-04-04T18:16:06.026574Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_file)\n",
    "vocab = pd.read_csv(vocab_file)\n",
    "vocab = dict(zip(vocab['word'], vocab['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5e7565def74fb11c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T18:13:22.147356Z",
     "start_time": "2025-04-04T18:13:22.121350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>tokenized_comment</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>explan edit made usernam hardcor metallica fan...</td>\n",
       "      <td>['explan', 'edit', 'made', 'usernam', 'hardcor...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>daww match background colour im seemingli stuc...</td>\n",
       "      <td>['daww', 'match', 'background', 'colour', 'im'...</td>\n",
       "      <td>[27, 28, 29, 30, 25, 31, 32, 33, 22, 34, 35, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man im really not trying to edit war its j...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hey man im realli tri edit war guy constantli ...</td>\n",
       "      <td>['hey', 'man', 'im', 'realli', 'tri', 'edit', ...</td>\n",
       "      <td>[38, 39, 25, 40, 41, 2, 42, 43, 44, 20, 45, 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>more i cant make any real suggestions on impr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cant make real suggest improv wonder section s...</td>\n",
       "      <td>['cant', 'make', 'real', 'suggest', 'improv', ...</td>\n",
       "      <td>[53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  0000997932d777bf  explanation why the edits made under my userna...   \n",
       "1  000103f0d9cfb60f  daww he matches this background colour im seem...   \n",
       "2  000113f07ec002fd  hey man im really not trying to edit war its j...   \n",
       "3  0001b41b1c6bb37e   more i cant make any real suggestions on impr...   \n",
       "\n",
       "   target                                    cleaned_comment  \\\n",
       "0     0.0  explan edit made usernam hardcor metallica fan...   \n",
       "1     0.0  daww match background colour im seemingli stuc...   \n",
       "2     0.0  hey man im realli tri edit war guy constantli ...   \n",
       "3     0.0  cant make real suggest improv wonder section s...   \n",
       "\n",
       "                                   tokenized_comment  \\\n",
       "0  ['explan', 'edit', 'made', 'usernam', 'hardcor...   \n",
       "1  ['daww', 'match', 'background', 'colour', 'im'...   \n",
       "2  ['hey', 'man', 'im', 'realli', 'tri', 'edit', ...   \n",
       "3  ['cant', 'make', 'real', 'suggest', 'improv', ...   \n",
       "\n",
       "                                            sequence  \n",
       "0  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
       "1  [27, 28, 29, 30, 25, 31, 32, 33, 22, 34, 35, 3...  \n",
       "2  [38, 39, 25, 40, 41, 2, 42, 43, 44, 20, 45, 46...  \n",
       "3  [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 6...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60f9a781e31ce43d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T18:16:47.281500Z",
     "start_time": "2025-04-04T18:16:47.266503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"[PAD]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14b058ba7c0305e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the current working directory\n",
    "BASE_DIR = Path().resolve().parent\n",
    "\n",
    "# Construct relative path to the data file\n",
    "data_path = BASE_DIR / \"data\" / \"processed.csv\"\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "df['sequence'] = df['sequence'].apply(ast.literal_eval)\n",
    "df['target'] = df['target'].astype(int)\n",
    "\n",
    "# Split\n",
    "\n",
    "def train_val_test_split(df, train_size=0.8, val_size=0.1, test_size=0.1, random_state=42):\n",
    "    assert abs(train_size + val_size + test_size - 1.0) < 1e-5, \"Splits must add to 1\"\n",
    "    \n",
    "    train_val, test = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "    train, val = train_test_split(train_val, test_size=val_size / (train_size + val_size), random_state=random_state)\n",
    "    return train, val, test\n",
    "\n",
    "train_data, val_data, test_data = train_val_test_split(df, train_size=0.8, val_size=0.1, test_size=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a3fcc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataframe, pad_len=100, pad_value=0):\n",
    "        self.sequences = dataframe['sequence'].apply(\n",
    "            lambda x: x[:pad_len] + [pad_value] * (pad_len - len(x)) if len(x) < pad_len else x[:pad_len] # padding\n",
    "        ).tolist()\n",
    "        self.labels = dataframe['target'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx): # conversion to tensor\n",
    "        return torch.tensor(self.sequences[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "809cb7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = vocab[\"[PAD]\"]\n",
    "MAXLEN = 100\n",
    "\n",
    "train_dataset = TextDataset(train_data, pad_len=MAXLEN, pad_value=PAD_IDX)\n",
    "val_dataset   = TextDataset(val_data, pad_len=MAXLEN, pad_value=PAD_IDX)\n",
    "test_dataset  = TextDataset(test_data, pad_len=MAXLEN, pad_value=PAD_IDX)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "efde139b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Original (len=5): [1694, 1764, 10598, 590, 6806]\n",
      "ðŸ”¸ Padded   (len=100): [1694, 1764, 10598, 590, 6806, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸ”¹ Original (len=23): [1035, 2010, 323, 65, 95, 265, 896, 903, 79, 611, 977, 325, 2010, 1035, 3378, 260, 877, 457, 755, 23, 68, 113, 1094]\n",
      "ðŸ”¸ Padded   (len=100): [1035, 2010, 323, 65, 95, 265, 896, 903, 79, 611, 977, 325, 2010, 1035, 3378, 260, 877, 457, 755, 23, 68, 113, 1094, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸ”¹ Original (len=46): [35, 36, 37, 735, 1965, 580, 46, 6833, 208, 156, 1965, 580, 11541, 226, 5891, 365, 1388, 409, 82, 2100, 715, 307, 507, 580, 121, 153, 1458, 1208, 715, 1482, 11542, 1275, 6033, 1900, 67, 45, 82, 89, 2240, 2242, 338, 5190, 6833, 1262, 1263, 34]\n",
      "ðŸ”¸ Padded   (len=100): [35, 36, 37, 735, 1965, 580, 46, 6833, 208, 156, 1965, 580, 11541, 226, 5891, 365, 1388, 409, 82, 2100, 715, 307, 507, 580, 121, 153, 1458, 1208, 715, 1482, 11542, 1275, 6033, 1900, 67, 45, 82, 89, 2240, 2242, 338, 5190, 6833, 1262, 1263, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### To test how padding is applied\n",
    "\n",
    "\n",
    "# Select a few examples to inspect\n",
    "sample_seqs = train_data['sequence'].iloc[:3].tolist()\n",
    "\n",
    "# Function to pad\n",
    "def pad_sequence(seq, pad_len, pad_value=PAD_IDX):\n",
    "    if len(seq) < pad_len:\n",
    "        return seq + [pad_value] * (pad_len - len(seq))\n",
    "    else:\n",
    "        return seq[:pad_len]\n",
    "\n",
    "# Show comparison\n",
    "for i, seq in enumerate(sample_seqs):\n",
    "    padded = pad_sequence(seq, MAXLEN, pad_value=PAD_IDX)\n",
    "    print(f\"ðŸ”¹ Original (len={len(seq)}): {seq}\")\n",
    "    print(f\"ðŸ”¸ Padded   (len={len(padded)}): {padded}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f878676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb5ea552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LightweightDNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(LightweightDNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=PAD_IDX)\n",
    "        self.fc1 = nn.Linear(embedding_dim, 16)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)              # [batch_size, seq_len, embed_dim]\n",
    "        pooled = embedded.mean(dim=1)             # Global average pooling\n",
    "        x = F.relu(self.fc1(pooled))\n",
    "        return torch.sigmoid(self.fc2(x)).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0d47fb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 49.7449\n",
      "Epoch 2, Loss: 33.8140\n",
      "Epoch 3, Loss: 24.9441\n",
      "Epoch 4, Loss: 22.7092\n",
      "Epoch 5, Loss: 21.2391\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LightweightDNN(vocab_size=len(vocab), embedding_dim=64).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch_x)\n",
    "        loss = criterion(out, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
